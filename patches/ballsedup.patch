diff --git a/primitives.c b/primitives.c
diff --git a/shader.c b/shader.c
index 99a356f..0c08097 100644
--- a/shader.c
+++ b/shader.c
@@ -337,6 +337,36 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
         	S_0, 16, S_0, 0, S_0, 17, S_0, 1,
 	        S_0, 18, S_0, 2, S_0, 19, S_0, 3};
 
+	const vec_uchar16 get1 = (vec_uchar16) {
+        	S_0, 20, S_0, 4, S_0, 21, S_0, 5,
+	        S_0, 22, S_0, 6, S_0, 23, S_0, 7};
+
+	const vec_uchar16 copy_as_is = (vec_uchar16) {
+		0,1,2,3, 4,5,6,7, 8,9,10,11, 12,13,14,15};
+
+	const vec_uchar16 copy_as_is_other_reg = (vec_uchar16) {
+		16,17,18,19, 20,21,22,23, 24,25,26,27, 28,29,30,31};
+
+	const vec_uchar16 fixed_hi_byte_to_splats_int = (vec_uchar16) {
+		0,0,0,0, 4,4,4,4, 8,8,8,8, 12,12,12,12};
+
+	const vec_uchar16 fixed_lo_0_byte_to_splats_int = (vec_uchar16) {
+		3,3,3,3, 3,3,3,3, 3,3,3,3, 3,3,3,3}; 
+	const vec_uchar16 fixed_lo_1_byte_to_splats_int = (vec_uchar16) {
+		7,7,7,7, 7,7,7,7, 7,7,7,7, 7,7,7,7};
+	const vec_uchar16 fixed_lo_2_byte_to_splats_int = (vec_uchar16) {
+		11,11,11,11, 11,11,11,11, 11,11,11,11, 11,11,11,11};
+	const vec_uchar16 fixed_lo_3_byte_to_splats_int = (vec_uchar16) {
+		15,15,15,15, 15,15,15,15, 15,15,15,15, 15,15,15,15};
+
+	const vec_uchar16 fixed_lo_byte_to_splats_int = (vec_uchar16) {
+		3,3,3,3, 7,7,7,7, 11,11,11,11, 15,15,15,15};
+
+	const vec_uint4 xf80 = (vec_uint4) 0xf80;
+	const vec_uint4 x7c = (vec_uint4) 0x7c;
+	const vec_uint4 x7 = (vec_uint4) 0x7;
+	const vec_uint4 x38 = (vec_uint4) 0x38;
+
 	do {
 		vec_uint4 uAa = (vec_uint4) Aa;
 		vec_uint4 uAb = (vec_uint4) Ab;
@@ -356,8 +386,8 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 			vec_float4 t_s = extract(tri->s, tAa, tAb, tAc);
 			vec_float4 t_t = extract(tri->t, tAa, tAb, tAc);
 
-			vec_uint4 s_blk = spu_and(spu_rlmask(spu_convtu(t_s,32),-29), 0x7);	//24+5
-			vec_uint4 t_blk = spu_and(spu_rlmask(spu_convtu(t_t,32),-26), 0x38);	//24+2
+			vec_uint4 s_blk = spu_and(spu_rlmask(spu_convtu(t_s,32),-29), x7);	//24+5
+			vec_uint4 t_blk = spu_and(spu_rlmask(spu_convtu(t_t,32),-26), x38);	//24+2
 			vec_uint4 block_id = spu_add(tex_id_base,spu_or(s_blk,t_blk));
 
 			vec_ushort8 copy_cmp_0 = spu_shuffle(block_id,block_id,shuf_cmp_0);
@@ -398,7 +428,8 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 			//vec_uint4 cache_not_found = spu_and(pixel,spu_cmpeq(cache,spu_splats((unsigned int)32)));
 			vec_uint4 cache_not_found = spu_cmpeq(cache,spu_splats((unsigned int)32));
 			unsigned int cache_orx = spu_extract(spu_orx(cache_not_found),0);
-			if (__builtin_expect(cache_orx,0)) {  // amazingly gcc does move this out of the loop :)
+			// if (__builtin_expect(cache_orx,0)) {  // amazingly gcc does move this out of the loop :)
+			if (cache_orx) {  // amazingly gcc does move this out of the loop :)
 				vec_uint4 s = spu_rlmask(spu_convtu(t_s,32),-29);
 				vec_uint4 t = spu_rlmask(spu_convtu(t_t,32),-29);
 				return loadMissingTextures(self, block, active, tag,
@@ -408,8 +439,8 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 
 			// pixel is mask of 1's where we want to draw
 		
-			vec_uint4 s_sub = spu_and(spu_rlmask(spu_convtu(t_s,32),-17), 0xf80);	//19-2
-			vec_uint4 t_sub = spu_and(spu_rlmask(spu_convtu(t_t,32),-22), 0x7c);	//24-2
+			vec_uint4 s_sub = spu_and(spu_rlmask(spu_convtu(t_s,32),-17), xf80);	//19-2yy
+			vec_uint4 t_sub = spu_and(spu_rlmask(spu_convtu(t_t,32),-22), x7c);	//24-2
 			vec_uint4 sub_block_pixel = spu_or(s_sub,t_sub);
 
 			vec_uint4 tex_ofs = spu_mulo( (vec_ushort8)cache,(vec_ushort8)((33*32+4*40)*4));
@@ -421,8 +452,8 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 			vec_uint4 addr01 = spu_add(addr00, (unsigned int)(32*4));
 
 			// if x<32
-			vec_uint4 addr10a = spu_add(addr00, (unsigned int)4);
-			vec_uint4 addr11a = spu_add(addr00, (unsigned int)(32*4+4));
+			vec_uint4 addr10a = spu_add(addr00, (unsigned int)16);
+			vec_uint4 addr11a = spu_add(addr00, (unsigned int)(32*4+16));
 
 			// if x==32
 			vec_uint4 sb_sub = spu_and(spu_rlmask(spu_convtu(t_s,32),-20), 0x1f0);
@@ -430,48 +461,66 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 			vec_uint4 addr11b = spu_add(addr10b, spu_splats((unsigned int)16));
 
 			// decision
-			vec_uint4 is_x_32 = spu_cmpeq(t_sub,0x7c);
+			vec_uint4 is_x_32 = spu_cmpeq(t_sub,0x1f0);
 			vec_uint4 addr10 = spu_sel(addr10a,addr10b,is_x_32);
 			vec_uint4 addr11 = spu_sel(addr11a,addr11b,is_x_32);
 
 			unsigned int local_tex_base = (unsigned int)&textureCache;
-			// load pixel data for all 4 pixels
-			unsigned long pixel0_00 = *((u32*)(local_tex_base+spu_extract(addr00,0)));
-			unsigned long pixel1_00 = *((u32*)(local_tex_base+spu_extract(addr00,1)));
-			unsigned long pixel2_00 = *((u32*)(local_tex_base+spu_extract(addr00,2)));
-			unsigned long pixel3_00 = *((u32*)(local_tex_base+spu_extract(addr00,3)));
-//			vec_uint4 colour00 = {pixel0_00, pixel1_00, pixel2_00, pixel3_00};
-		
-			unsigned long pixel0_01 = *((u32*)(local_tex_base+spu_extract(addr01,0)));
-			unsigned long pixel1_01 = *((u32*)(local_tex_base+spu_extract(addr01,1)));
-			unsigned long pixel2_01 = *((u32*)(local_tex_base+spu_extract(addr01,2)));
-			unsigned long pixel3_01 = *((u32*)(local_tex_base+spu_extract(addr01,3)));
-//			vec_uint4 colour01 = {pixel0_01, pixel1_01, pixel2_01, pixel3_01};
-		
-			unsigned long pixel0_10 = *((u32*)(local_tex_base+spu_extract(addr10,0)));
-			unsigned long pixel1_10 = *((u32*)(local_tex_base+spu_extract(addr10,1)));
-			unsigned long pixel2_10 = *((u32*)(local_tex_base+spu_extract(addr10,2)));
-			unsigned long pixel3_10 = *((u32*)(local_tex_base+spu_extract(addr10,3)));
-//			vec_uint4 colour10 = {pixel0_10, pixel1_10, pixel2_10, pixel3_10};
-		
-			unsigned long pixel0_11 = *((u32*)(local_tex_base+spu_extract(addr11,0)));
-			unsigned long pixel1_11 = *((u32*)(local_tex_base+spu_extract(addr11,1)));
-			unsigned long pixel2_11 = *((u32*)(local_tex_base+spu_extract(addr11,2)));
-			unsigned long pixel3_11 = *((u32*)(local_tex_base+spu_extract(addr11,3)));
-//			vec_uint4 colour11 = {pixel0_11, pixel1_11, pixel2_11, pixel3_11};
-		
 
+			vec_uint4 quad0_00 = *((vec_uint4*)(local_tex_base+spu_extract(addr00,0)));
+			vec_uint4 quad0_01 = *((vec_uint4*)(local_tex_base+spu_extract(addr01,0)));
+			vec_uint4 quad0_10 = *((vec_uint4*)(local_tex_base+spu_extract(addr10,0)));
+			vec_uint4 quad0_11 = *((vec_uint4*)(local_tex_base+spu_extract(addr11,0)));
+
+			vec_uint4 quad1_00 = *((vec_uint4*)(local_tex_base+spu_extract(addr00,1)));
+			vec_uint4 quad1_01 = *((vec_uint4*)(local_tex_base+spu_extract(addr01,1)));
+			vec_uint4 quad1_10 = *((vec_uint4*)(local_tex_base+spu_extract(addr10,1)));
+			vec_uint4 quad1_11 = *((vec_uint4*)(local_tex_base+spu_extract(addr11,1)));
+
+			vec_uint4 quad2_00 = *((vec_uint4*)(local_tex_base+spu_extract(addr00,2)));
+			vec_uint4 quad2_01 = *((vec_uint4*)(local_tex_base+spu_extract(addr01,2)));
+			vec_uint4 quad2_10 = *((vec_uint4*)(local_tex_base+spu_extract(addr10,2)));
+			vec_uint4 quad2_11 = *((vec_uint4*)(local_tex_base+spu_extract(addr11,2)));
+
+			vec_uint4 quad3_00 = *((vec_uint4*)(local_tex_base+spu_extract(addr00,3)));
+			vec_uint4 quad3_01 = *((vec_uint4*)(local_tex_base+spu_extract(addr01,3)));
+			vec_uint4 quad3_10 = *((vec_uint4*)(local_tex_base+spu_extract(addr10,3)));
+			vec_uint4 quad3_11 = *((vec_uint4*)(local_tex_base+spu_extract(addr11,3)));
+
+/////////////////////
+			//vec_uint4 x_shuf_add = spu_and(spu_rlmask(spu_convtu(t_t,32),-28), (vec_uint4)0xc);
+			vec_uint4 x_shuf_add = spu_and(addr00, (vec_uint4)0xc);
+
+			vec_uint4 x_shuf0 = spu_add((vec_uint4)copy_as_is,spu_shuffle(x_shuf_add,(vec_uint4)copy_as_is_other_reg,fixed_lo_0_byte_to_splats_int));
+			vec_uint4 x_shuf1 = spu_add((vec_uint4)copy_as_is,spu_shuffle(x_shuf_add,(vec_uint4)copy_as_is_other_reg,fixed_lo_1_byte_to_splats_int));
+			vec_uint4 x_shuf2 = spu_add((vec_uint4)copy_as_is,spu_shuffle(x_shuf_add,(vec_uint4)copy_as_is_other_reg,fixed_lo_2_byte_to_splats_int));
+			vec_uint4 x_shuf3 = spu_add((vec_uint4)copy_as_is,spu_shuffle(x_shuf_add,(vec_uint4)copy_as_is_other_reg,fixed_lo_3_byte_to_splats_int));
+
+			vec_uint4 pixel0_0001 = spu_shuffle(quad0_00,quad0_01,(vec_uchar16)x_shuf0);
+			vec_uint4 pixel0_1011 = spu_shuffle(quad0_10,quad0_11,(vec_uchar16)x_shuf0);
+
+			vec_uint4 pixel1_0001 = spu_shuffle(quad1_00,quad1_01,(vec_uchar16)x_shuf1);
+			vec_uint4 pixel1_1011 = spu_shuffle(quad1_10,quad1_11,(vec_uchar16)x_shuf1);
+
+			vec_uint4 pixel2_0001 = spu_shuffle(quad2_00,quad2_01,(vec_uchar16)x_shuf2);
+			vec_uint4 pixel2_1011 = spu_shuffle(quad2_10,quad2_11,(vec_uchar16)x_shuf2);
+
+			vec_uint4 pixel3_0001 = spu_shuffle(quad3_00,quad3_01,(vec_uchar16)x_shuf3);
+			vec_uint4 pixel3_1011 = spu_shuffle(quad3_10,quad3_11,(vec_uchar16)x_shuf3);
+
+///////////
 			vec_uint4 s_pxofs = spu_and(spu_rlmask(spu_convtu(t_s,32),-16), (vec_uint4)0xff);
 			vec_uint4 t_pxofs = spu_and(spu_rlmask(spu_convtu(t_t,32),-16), (vec_uint4)0xff);
 
-//			s_pxofs = (vec_uint4) 0x80;
-//			t_pxofs = (vec_uint4) 0x1;
+		s_pxofs = (vec_uint4) 0;
+//		t_pxofs = (vec_uint4) 0;
+		t_pxofs = (vec_uint4) 0xff;
+
+			vec_short8 pixel01_ = (vec_short8) spu_shuffle((vec_uint4)pixel0_0001, (vec_uint4)pixel1_0001, get0);
+			vec_short8 pixel01_x = (vec_short8) spu_shuffle((vec_uint4)pixel0_0001, (vec_uint4)pixel1_0001, get1);
+			vec_short8 pixel01_xy = (vec_short8) spu_shuffle((vec_uint4)pixel0_1011, (vec_uint4)pixel1_1011, get1);
+			vec_short8 pixel01_y = (vec_short8) spu_shuffle((vec_uint4)pixel0_1011, (vec_uint4)pixel1_1011, get0);
 
-///////////
-			vec_short8 pixel01_ = (vec_short8) spu_shuffle((vec_uint4)pixel0_00, (vec_uint4)pixel1_00, get0);
-			vec_short8 pixel01_x = (vec_short8) spu_shuffle((vec_uint4)pixel0_01, (vec_uint4)pixel1_01, get0);
-			vec_short8 pixel01_xy = (vec_short8) spu_shuffle((vec_uint4)pixel0_11, (vec_uint4)pixel1_11, get0);
-			vec_short8 pixel01_y = (vec_short8) spu_shuffle((vec_uint4)pixel0_10, (vec_uint4)pixel1_10, get0);
 			vec_short8 pixel01_h = spu_sub(pixel01_x,pixel01_);
 			vec_short8 pixel01_yh = spu_sub(pixel01_xy,pixel01_y);
 
@@ -496,10 +545,11 @@ void* linearTextureMapFill(void* self, Block* block, ActiveBlock* active, int ta
 			vec_short8 pixel01_done = spu_add(pixel01_mm, pixel01_tm);
 
 ///////////
-			vec_short8 pixel23_ = (vec_short8) spu_shuffle((vec_uint4)pixel2_00, (vec_uint4)pixel3_00, get0);
-			vec_short8 pixel23_x = (vec_short8) spu_shuffle((vec_uint4)pixel2_01, (vec_uint4)pixel3_01, get0);
-			vec_short8 pixel23_xy = (vec_short8) spu_shuffle((vec_uint4)pixel2_11, (vec_uint4)pixel3_11, get0);
-			vec_short8 pixel23_y = (vec_short8) spu_shuffle((vec_uint4)pixel2_10, (vec_uint4)pixel3_10, get0);
+			vec_short8 pixel23_ = (vec_short8) spu_shuffle((vec_uint4)pixel2_0001, (vec_uint4)pixel3_0001, get0);
+			vec_short8 pixel23_x = (vec_short8) spu_shuffle((vec_uint4)pixel2_0001, (vec_uint4)pixel3_0001, get1);
+			vec_short8 pixel23_xy = (vec_short8) spu_shuffle((vec_uint4)pixel2_1011, (vec_uint4)pixel3_1011, get1);
+			vec_short8 pixel23_y = (vec_short8) spu_shuffle((vec_uint4)pixel2_1011, (vec_uint4)pixel3_1011, get0);
+
 			vec_short8 pixel23_h = spu_sub(pixel23_x,pixel23_);
 			vec_short8 pixel23_yh = spu_sub(pixel23_xy,pixel23_y);
 
